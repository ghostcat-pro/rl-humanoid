policy: MlpPolicy

device: cuda  # Use GPU (was: cpu)

# if no set the default would be [64,64] size of the hidden layers
policy_kwargs:
  net_arch: [256, 256]


hyperparams:
  learning_rate: 3.0e-4
  n_steps: 4096
  batch_size: 16384
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.005
  vf_coef: 0.25
  max_grad_norm: 0.5
