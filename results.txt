================================================================================
HUMANOID-V5 MODEL EVALUATION RESULTS
================================================================================
Total Models Evaluated: 7
Episodes per Model: 20
Evaluation Mode: Deterministic
================================================================================

SUMMARY TABLE
--------------------------------------------------------------------------------
Run             Total Steps     Mean Reward     Std Dev      Success   
--------------------------------------------------------------------------------
11-33-29        1.0M            489.76          ±64.03       0%        
12-17-01        1.0M            489.76          ±64.03       0%        
12-25-32        10.0M           6920.77         ±74.14       100%      
13-02-09        30.0M           9870.22         ±73.74       100%      
16-30-12        50.0M           7435.45         ±3955.75     75%       
17-47-25        50.0M           7435.45         ±3955.75     75%       
21-33-51        100.0M          4331.37         ±4075.44     40%       
--------------------------------------------------------------------------------

RANKING (by Mean Reward)
--------------------------------------------------------------------------------
1. 13-02-09 (30M steps): 9870.22
2. 16-30-12 (50M steps): 7435.45
3. 17-47-25 (50M steps): 7435.45
4. 12-25-32 (10M steps): 6920.77
5. 21-33-51 (100M steps): 4331.37
6. 11-33-29 (1M steps): 489.76
7. 12-17-01 (1M steps): 489.76

BEST MODEL
--------------------------------------------------------------------------------
Run Directory: outputs/2025-10-28/13-02-09
Timestamp: 13-02-09
Mean Reward: 9870.22 ± 73.74
Min/Max Reward: 9716.07 / 9974.48
Median Reward: 9888.45
Mean Episode Length: 1000.00 steps
Success Rate: 100.0%

Training Configuration:
  Total Timesteps: 30,000,000
  Environment: Humanoid-v5
  Num Envs: 16
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Entropy Coefficient: 0.005

================================================================================
DETAILED RESULTS
================================================================================

Run Directory: outputs/2025-10-28/11-33-29
Timestamp: 11-33-29
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 1,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 8
  Policy: MlpPolicy
  Device: N/A
  Learning Rate: 0.0003
  Batch Size: 8192
  N Steps: 2048
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.0
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 489.76 ± 64.03
  Min Reward: 403.95
  Max Reward: 656.61
  Median Reward: 471.98
  Mean Episode Length: 94.05 steps
  Success Rate (>5000): 0.0%

================================================================================

Run Directory: outputs/2025-10-28/12-17-01
Timestamp: 12-17-01
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 1,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 8
  Policy: MlpPolicy
  Device: N/A
  Learning Rate: 0.0003
  Batch Size: 8192
  N Steps: 2048
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.0
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 489.76 ± 64.03
  Min Reward: 403.95
  Max Reward: 656.61
  Median Reward: 471.98
  Mean Episode Length: 94.05 steps
  Success Rate (>5000): 0.0%

================================================================================

Run Directory: outputs/2025-10-28/12-25-32
Timestamp: 12-25-32
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 10,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 16
  Policy: MlpPolicy
  Device: N/A
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.005
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 6920.77 ± 74.14
  Min Reward: 6758.55
  Max Reward: 7085.21
  Median Reward: 6914.11
  Mean Episode Length: 1000.00 steps
  Success Rate (>5000): 100.0%

================================================================================

Run Directory: outputs/2025-10-28/13-02-09
Timestamp: 13-02-09
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 30,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 16
  Policy: MlpPolicy
  Device: cuda
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.005
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 9870.22 ± 73.74
  Min Reward: 9716.07
  Max Reward: 9974.48
  Median Reward: 9888.45
  Mean Episode Length: 1000.00 steps
  Success Rate (>5000): 100.0%

================================================================================

Run Directory: outputs/2025-10-28/16-30-12
Timestamp: 16-30-12
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 50,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 16
  Policy: MlpPolicy
  Device: cuda
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.005
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 7435.45 ± 3955.75
  Min Reward: 445.67
  Max Reward: 9882.13
  Median Reward: 9713.14
  Mean Episode Length: 773.95 steps
  Success Rate (>5000): 75.0%

================================================================================

Run Directory: outputs/2025-10-28/17-47-25
Timestamp: 17-47-25
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 50,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 16
  Policy: MlpPolicy
  Device: cuda
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.005
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 7435.45 ± 3955.75
  Min Reward: 445.67
  Max Reward: 9882.13
  Median Reward: 9713.14
  Mean Episode Length: 773.95 steps
  Success Rate (>5000): 75.0%

================================================================================

Run Directory: outputs/2025-10-28/21-33-51
Timestamp: 21-33-51
--------------------------------------------------------------------------------

Training Configuration:
  Total Timesteps: 100,000,000
  Environment: Humanoid-v5
  Num Parallel Envs: 16
  Policy: MlpPolicy
  Device: cuda
  Learning Rate: 0.00025
  Batch Size: 8192
  N Steps: 1024
  N Epochs: 10
  Gamma: 0.99
  GAE Lambda: 0.95
  Clip Range: 0.2
  Entropy Coef: 0.005
  Value Function Coef: 0.5
  Max Grad Norm: 0.5
  VecNormalize Enabled: True
  Checkpoint Every: 250,000 steps

Evaluation Results:
  Episodes: 20
  Mean Reward: 4331.37 ± 4075.44
  Min Reward: 485.45
  Max Reward: 9852.86
  Median Reward: 1346.58
  Mean Episode Length: 475.00 steps
  Success Rate (>5000): 40.0%

================================================================================

